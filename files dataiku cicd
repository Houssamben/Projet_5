What You Need to Know First
ðŸ”¹ What Are Macros in Dataiku?

Macros are Python scripts packaged in a plugin that automate tasks.
They can be run manually, in scenarios, or triggered externally (e.g., via GitLab).
Each macro has:

runnable.py: the Python logic.
runnable.json: metadata and parameters.


api-deployment-plugin/
â”œâ”€â”€ plugin.json
â”œâ”€â”€ python-runnables/
â”‚   â”œâ”€â”€ package-api/
â”‚   â”‚   â”œâ”€â”€ runnable.py
â”‚   â”‚   â””â”€â”€ runnable.json
â”‚   â””â”€â”€ deploy-api/
â”‚       â”œâ”€â”€ runnable.py
â”‚       â””â”€â”€ runnable.json

Macro 1: Package & Publish API
runnable.py

from dataiku.runnables import Runnable
import dataikuapi

class PackageAndPublishAPI(Runnable):
    def __init__(self, project_key, config, plugin_config):
        self.project_key = project_key
        self.config = config

    def run(self, progress_callback):
        client = dataikuapi.DSSClient(self.config["design_node_url"], self.config["api_key"])
        service = client.get_project(self.project_key).get_api_service(self.config["service_id"])
        
        # Create a new version
        version_id = service.create_version()
        
        # Publish to API Deployer
        service.publish_package(version_id)
        
        return f"Packaged and published version: {version_id}"


runnable.json:
{
  "meta": {
    "label": "Package & Publish API",
    "description": "Creates and publishes a version of the API service",
    "icon": "icon-cube"
  },
  "params": [
    { "name": "design_node_url", "label": "Design Node URL", "type": "STRING" },
    { "name": "api_key", "label": "API Key", "type": "STRING" },
    { "name": "service_id", "label": "API Service ID", "type": "STRING" }
  ],
  "resultType": "STRING"
}

Macro 2: Deploy API Version

runnable.py

from dataiku.runnables import Runnable
import dataikuapi

class DeployAPI(Runnable):
    def __init__(self, project_key, config, plugin_config):
        self.project_key = project_key
        self.config = config

    def run(self, progress_callback):
        client = dataikuapi.DSSClient(self.config["design_node_url"], self.config["api_key"])
        deployer = client.get_apideployer()
        
        # Create deployment
        deployment = deployer.create_deployment(
            deployment_id=self.config["deployment_id"],
            service_id=self.config["service_id"],
            infra_id=self.config["infra_id"],
            version=self.config["version_id"]
        )
        
        # Start deployment
        deployment.start_update()
        
        return f"Deployed version {self.config['version_id']} to infrastructure {self.config['infra_id']}"


runnable.json

{
  "meta": {
    "label": "Deploy API Version",
    "description": "Deploys a published API version to an infrastructure",
    "icon": "icon-rocket"
  },
  "params": [
    { "name": "design_node_url", "label": "Design Node URL", "type": "STRING" },
    { "name": "api_key", "label": "API Key", "type": "STRING" },
    { "name": "service_id", "label": "API Service ID", "type": "STRING" },
    { "name": "version_id", "label": "Version ID", "type": "STRING" },
    { "name": "infra_id", "label": "Infrastructure ID", "type": "STRING" },
    { "name": "deployment_id", "label": "Deployment ID", "type": "STRING" }
  ],
  "resultType": "STRING"
}


Step 2: Integrate with GitLab CI/CD
Example .gitlab-ci.yml

stages:
  - package
  - deploy
package_api:
  stage: package
  script:
    - python scripts/package_api.py

deploy_api:
  stage: deploy
  script:
    - python scripts/deploy_api.py


scripts/package_api.py

from dataikuapi import DSSClient

client = DSSClient("http://your-design-node:port", "your-api-key")
project = client.get_project("YOUR_PROJECT_KEY")
macro = project.get_macro("api-deployment-plugin.package-api")
macro.run(params={
    "design_node_url": "http://your-design-node:port",
    "api_key": "your-api-key",
    "service_id": "your-service-id"
})

scripts/deploy_api.py

from dataikuapi import DSSClient

client = DSSClient("http://your-design-node:port", "your-api-key")
project = client.get_project("YOUR_PROJECT_KEY")
macro = project.get_macro("api-deployment-plugin.deploy-api")
macro.run(params={
    "design_node_url": "http://your-design-node:port",
    "api_key": "your-api-key",
    "service_id": "your-service-id",
    "version_id": "your-version-id",
    "infra_id": "your-infra-id",
    "deployment_id": "your-deployment-id"
})






code : 


def get_object_fields(obj):
    fields = []
    for attr in dir(obj):
        if not attr.startswith("_"):  # Skip private/internal attributes
            try:
                value = getattr(obj, attr)
                fields.append((attr, value))
            except Exception as e:
                fields.append((attr, f"<Error: {e}>"))
    return fields

# Example usage:
client = dataiku.api_client()
deployer_object = client.get_apideployer()
fields_list = get_object_fields(deployer_object)

# Print the list
for key, value in fields_list:
    print(f"{key}: {value}")




indent = 0
for attr in dir(deployer):
    if not attr.startswith("__"):
        try:
            value = getattr(deployer, attr)
            print(" " * indent + f"{attr}: {value}")
            
            if hasattr(value, "__dict__"):
                print(" " * indent + f"â†³ Inspecting {attr}...")
                for sub_attr in dir(value):
                    if not sub_attr.startswith("__"):
                        try:
                            sub_value = getattr(value, sub_attr)
                            print(" " * (indent + 4) + f"{sub_attr}: {sub_value}")
                        except Exception as e:
                            print(" " * (indent + 4) + f"{sub_attr}: <error> ({e})")
        except Exception as e:
            print(f"{attr}: <error retrieving value> ({e})")






import re

def extract_connection_name(trigram, connections_list, connection_type):
    """
    Extracts connection names that contain the trigram and match the given connection type.

    Args:
        trigram (str): The 3-letter trigram (e.g., "ave").
        connections_list (list): List of connection names.
        connection_type (str): The type of connection to match.

    Returns:
        list: Matching connection names.
    """
    # Validate trigram length (optional)
    if len(trigram) != 3:
        raise ValueError("Trigram must be exactly 3 characters long.")

    # Compile regex for trigram search (case-insensitive)
    trigram_pattern = re.compile(rf"\b{trigram}\b", re.IGNORECASE)

    matching_connections = []
    for connection in connections_list:
        if get_connection_type(connection) == connection_type:
            if trigram_pattern.search(connection):
                matching_connections.append(connection)

    return matching_connections



# VÃ©rifier si la version est publiÃ©e avant dÃ©ploiement
api_deployer = client_deployer.get_apideployer()
published_versions = api_deployer.list_packages(service_id)  # Liste des packages publiÃ©s pour ce service

if recent_Api_version not in [pkg["id"] for pkg in published_versions]:
    return f"Version {recent_Api_version} n'est pas publiÃ©e, dÃ©ploiement annulÃ©."



if (api_version == "" or api_version is None or deploy_all_services):
    recent_Api_version = f"v{define_api_version(api_service, stage)}_{stage}"
else:
    api_deployer = client_deployer.get_apideployer()
    published_ids = {pkg["id"] for pkg in api_deployer.list_packages(service_id)}
    recent_Api_version = (
        api_version
        if api_version in published_ids
        else f"v{define_api_version(api_service, stage)}_{stage}"
    )


